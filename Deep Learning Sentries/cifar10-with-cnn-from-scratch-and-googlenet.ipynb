{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nLet's break the notebook into separate steps. Feel free to navigate the notebook and comment if you have any suggestions.\n\nStep 0: Import Datasets <br />\nStep 1: Define dataloader and visualization<br />\nStep 2: Create a CNN to Classify (from Scratch)<br />\nStep 3: Create a CNN to Classify  (using Transfer Learning)<br />\nStep 4: Test","metadata":{}},{"cell_type":"markdown","source":"# Step 0: Imports\n\n1.   List item\n2.   List item\n\n\n\nAt first we need to import the libraries. It is considered as standard imports for pytorch.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nfrom torchvision.utils import make_grid\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nfrom PIL import Image\nfrom IPython.display import display\n\nimport cv2\n\nfrom PIL import ImageFile\nimport torchvision.transforms as transforms\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport glob\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:41:49.346226Z","iopub.execute_input":"2021-11-19T13:41:49.346593Z","iopub.status.idle":"2021-11-19T13:41:51.101403Z","shell.execute_reply.started":"2021-11-19T13:41:49.346480Z","shell.execute_reply":"2021-11-19T13:41:51.100502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will be using this function mostly everywhere to run our experiments deterministically. Random functions of Numpy and Pandas will behave deterministically after this. To learn more about Deterministic Neural Networks please check out [this notebook](https://www.kaggle.com/bminixhofer/deterministic-neural-networks-using-pytorch)","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything(42)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:41:51.103333Z","iopub.execute_input":"2021-11-19T13:41:51.103537Z","iopub.status.idle":"2021-11-19T13:41:51.113006Z","shell.execute_reply.started":"2021-11-19T13:41:51.103512Z","shell.execute_reply":"2021-11-19T13:41:51.112098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Have you wondered about why they use 42? Do you want to know about the reason behind 42? Look [Here ](https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life.2C_the_Universe_and_Everything_.2842.29):p","metadata":{}},{"cell_type":"markdown","source":"# Step 1: Define dataloader and visualization\n\nSince the dataset is available on pytorch dataset class so we will be downloading it from there and store on our kaggle space. ","metadata":{}},{"cell_type":"code","source":"#First let's define our data augmentation rules or transforms\n\n# define transformations for train\ntrain_transform = transforms.Compose([\n    transforms.RandomRotation(30),\n    transforms.RandomHorizontalFlip(p=.30),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n\n# define transformations for test\n# for test we dont need much of augmentations other than converting to tensors and normalizing the pictures\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:41:51.114381Z","iopub.execute_input":"2021-11-19T13:41:51.114956Z","iopub.status.idle":"2021-11-19T13:41:51.123456Z","shell.execute_reply.started":"2021-11-19T13:41:51.114920Z","shell.execute_reply":"2021-11-19T13:41:51.122417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"to use unverified ssl add this to your code: \n\\\n\\\n``import ssl\nssl._create_default_https_context = ssl._create_unverified_context``","metadata":{}},{"cell_type":"code","source":"import ssl\nssl._create_default_https_context = ssl._create_unverified_context\n\ntrain_data = datasets.CIFAR10('./cifar10/', train=True,\n                              download=True, transform=train_transform)\ntest_data = datasets.CIFAR10('./cifar10/', train=False,\n                             download=True, transform=test_transform)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:41:51.126167Z","iopub.execute_input":"2021-11-19T13:41:51.126508Z","iopub.status.idle":"2021-11-19T13:41:58.995061Z","shell.execute_reply.started":"2021-11-19T13:41:51.126465Z","shell.execute_reply":"2021-11-19T13:41:58.994116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of subprocesses to use for data loading\nnum_workers = 0\n\n#TODO\n\n\n# how many samples per batch to load\nbatch_size = 42\n\n# percentage of training set to use as validation\nvalid_size = 0.2","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:41:58.996271Z","iopub.execute_input":"2021-11-19T13:41:58.997215Z","iopub.status.idle":"2021-11-19T13:41:59.000639Z","shell.execute_reply.started":"2021-11-19T13:41:58.997167Z","shell.execute_reply":"2021-11-19T13:41:59.000066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dividing the training dataset further for validation set\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:41:59.001558Z","iopub.execute_input":"2021-11-19T13:41:59.001791Z","iopub.status.idle":"2021-11-19T13:41:59.020699Z","shell.execute_reply.started":"2021-11-19T13:41:59.001765Z","shell.execute_reply":"2021-11-19T13:41:59.019600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:41:59.021720Z","iopub.execute_input":"2021-11-19T13:41:59.022598Z","iopub.status.idle":"2021-11-19T13:41:59.034963Z","shell.execute_reply.started":"2021-11-19T13:41:59.022515Z","shell.execute_reply":"2021-11-19T13:41:59.034248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  data loaders (combine dataset and sampler)\n#Dataloader provides an iterable over the specified dataset by combining a dataset with a sampler.\n # TODO: One has been done for you\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n    sampler=train_sampler, num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n    sampler=valid_sampler, num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:41:59.037111Z","iopub.execute_input":"2021-11-19T13:41:59.037799Z","iopub.status.idle":"2021-11-19T13:41:59.047751Z","shell.execute_reply.started":"2021-11-19T13:41:59.037752Z","shell.execute_reply":"2021-11-19T13:41:59.046878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n           'dog', 'frog', 'horse', 'ship', 'truck']","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:41:59.049149Z","iopub.execute_input":"2021-11-19T13:41:59.049941Z","iopub.status.idle":"2021-11-19T13:41:59.060070Z","shell.execute_reply.started":"2021-11-19T13:41:59.049894Z","shell.execute_reply":"2021-11-19T13:41:59.059103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizations","metadata":{}},{"cell_type":"code","source":"#  function to un-normalize and display an image\ndef imshow(img):\n    img = img / 2 + 0.5  # unnormalize\n    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:41:59.064263Z","iopub.execute_input":"2021-11-19T13:41:59.064826Z","iopub.status.idle":"2021-11-19T13:41:59.071908Z","shell.execute_reply.started":"2021-11-19T13:41:59.064769Z","shell.execute_reply":"2021-11-19T13:41:59.070993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\n# display 20 images\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    imshow(images[idx])\n    ax.set_title(classes[labels[idx]])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:41:59.073341Z","iopub.execute_input":"2021-11-19T13:41:59.074368Z","iopub.status.idle":"2021-11-19T13:42:00.268548Z","shell.execute_reply.started":"2021-11-19T13:41:59.074323Z","shell.execute_reply":"2021-11-19T13:42:00.267662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"as shown, we have flipped images because of the image transforms","metadata":{}},{"cell_type":"code","source":"# let's look into details of normalized RGB\n\nrgb_img = np.squeeze(images[7])\nchannels = ['red channel', 'green channel', 'blue channel']\n\nfig = plt.figure(figsize = (36, 36)) \nfor idx in np.arange(rgb_img.shape[0]):\n    ax = fig.add_subplot(1, 3, idx + 1)\n    img = rgb_img[idx]\n    ax.imshow(img, cmap='gray')\n    ax.set_title(channels[idx])\n    width, height = img.shape\n    thresh = img.max()/2.5\n    for x in range(width):\n        for y in range(height):\n            val = round(img[x][y],2) if img[x][y] !=0 else 0\n            ax.annotate(str(val), xy=(y,x),\n                    horizontalalignment='center',\n                    verticalalignment='center', size=8,\n                    color='white' if img[x][y]<thresh else 'black')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:42:00.270019Z","iopub.execute_input":"2021-11-19T13:42:00.270786Z","iopub.status.idle":"2021-11-19T13:42:21.323688Z","shell.execute_reply.started":"2021-11-19T13:42:00.270744Z","shell.execute_reply":"2021-11-19T13:42:21.322744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: Create a CNN to Classify (from Scratch)<br />\n","metadata":{}},{"cell_type":"code","source":"# check if CUDA is available\nuse_gpu = torch.cuda.is_available()\n\nif  use_gpu:\n    print('CUDA is available.  Training on CPU ...')\nelse:\n    print('CUDA is not available!  Training on GPU ...')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:42:21.324921Z","iopub.execute_input":"2021-11-19T13:42:21.325155Z","iopub.status.idle":"2021-11-19T13:42:21.331058Z","shell.execute_reply.started":"2021-11-19T13:42:21.325128Z","shell.execute_reply":"2021-11-19T13:42:21.330142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the CNN architecture\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # convolutional layer (sees 32x32x3 image tensor)\n        # TODO: Define your model\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n        \n        self.pool = nn.MaxPool2d(2, 2)\n        \n        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n        self.fc2 = nn.Linear(500, 10)\n        \n        self.dropout = nn.Dropout(0.25)\n        \n\n    def forward(self, x):\n        # TODO Define Forward pass\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        \n        x = x.view(-1, 64 * 4 * 4)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# create a complete CNN\nmodel = Net()\nprint(model)\n\n# move tensors to GPU if CUDA is available\n# TODO","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:42:21.332941Z","iopub.execute_input":"2021-11-19T13:42:21.333475Z","iopub.status.idle":"2021-11-19T13:42:21.359399Z","shell.execute_reply.started":"2021-11-19T13:42:21.333431Z","shell.execute_reply":"2021-11-19T13:42:21.358323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:42:21.361679Z","iopub.execute_input":"2021-11-19T13:42:21.362283Z","iopub.status.idle":"2021-11-19T13:42:31.949052Z","shell.execute_reply.started":"2021-11-19T13:42:21.362234Z","shell.execute_reply":"2021-11-19T13:42:31.948305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's see the model\nfrom torchsummary import summary\nsummary(model, input_size=(3, 32, 32))","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:42:31.950641Z","iopub.execute_input":"2021-11-19T13:42:31.950913Z","iopub.status.idle":"2021-11-19T13:42:32.054431Z","shell.execute_reply.started":"2021-11-19T13:42:31.950878Z","shell.execute_reply":"2021-11-19T13:42:32.053812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  loss function (categorical cross-entropy)\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:42:32.055561Z","iopub.execute_input":"2021-11-19T13:42:32.056178Z","iopub.status.idle":"2021-11-19T13:42:32.061527Z","shell.execute_reply.started":"2021-11-19T13:42:32.056144Z","shell.execute_reply":"2021-11-19T13:42:32.060312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the model","metadata":{}},{"cell_type":"code","source":"# number of epochs to train the model\nn_epochs = 30\n\nvalid_loss_min = np.Inf # track change in validation loss\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    model.train()\n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        if use_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval()\n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if use_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    train_loss = train_loss/len(train_loader.sampler)\n    valid_loss = valid_loss/len(valid_loader.sampler)\n        \n    # print training/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model_cifar.pt')\n        valid_loss_min = valid_loss","metadata":{"execution":{"iopub.status.busy":"2021-11-19T13:42:32.063302Z","iopub.execute_input":"2021-11-19T13:42:32.063841Z","iopub.status.idle":"2021-11-19T14:01:44.675796Z","shell.execute_reply.started":"2021-11-19T13:42:32.063795Z","shell.execute_reply":"2021-11-19T14:01:44.674708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3: Create a CNN to Classify (using Transfer Learning)","metadata":{}},{"cell_type":"markdown","source":"We will be using GoogLeNet for transfer learning. Read the [paper](https://arxiv.org/abs/1409.4842) to learn more about GoogLeNet. ","metadata":{}},{"cell_type":"code","source":"#TODO \nmodel_transfer = models.googlenet(pretrained=True) #Get googLeNet from torch.models","metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:01:44.679575Z","iopub.execute_input":"2021-11-19T14:01:44.679893Z","iopub.status.idle":"2021-11-19T14:01:48.091497Z","shell.execute_reply.started":"2021-11-19T14:01:44.679859Z","shell.execute_reply":"2021-11-19T14:01:48.090496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model_transfer)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:01:48.093400Z","iopub.execute_input":"2021-11-19T14:01:48.093718Z","iopub.status.idle":"2021-11-19T14:01:48.103612Z","shell.execute_reply.started":"2021-11-19T14:01:48.093676Z","shell.execute_reply":"2021-11-19T14:01:48.102549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in model_transfer.parameters():\n    param.requires_grad = False\n    \n# replace the last fully connected layer with a Linnear layer 133 output\nin_features = model_transfer.fc.in_features\n#TODO\n# Fill out the out feature that we need\nmodel_transfer.fc = nn.Linear(in_features,10 )\n\nif use_gpu:\n    model_transfer = model_transfer.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:01:48.105434Z","iopub.execute_input":"2021-11-19T14:01:48.105759Z","iopub.status.idle":"2021-11-19T14:01:48.116122Z","shell.execute_reply.started":"2021-11-19T14:01:48.105718Z","shell.execute_reply":"2021-11-19T14:01:48.115265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(model_transfer, input_size=(3, 32, 32))","metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:01:48.117749Z","iopub.execute_input":"2021-11-19T14:01:48.118068Z","iopub.status.idle":"2021-11-19T14:01:48.243901Z","shell.execute_reply.started":"2021-11-19T14:01:48.118027Z","shell.execute_reply":"2021-11-19T14:01:48.242910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nmodel_transfer_grad_paramaters = filter(lambda p: p.requires_grad, model_transfer.parameters())\noptimizer = torch.optim.Adam(model_transfer_grad_paramaters, lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:01:48.247206Z","iopub.execute_input":"2021-11-19T14:01:48.247441Z","iopub.status.idle":"2021-11-19T14:01:48.254098Z","shell.execute_reply.started":"2021-11-19T14:01:48.247413Z","shell.execute_reply":"2021-11-19T14:01:48.252924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of epochs to train the model\nn_epochs = 10\n\nvalid_loss_min = np.Inf # track change in validation loss\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    model_transfer.train()\n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        if use_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model_transfer(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    model_transfer.eval()\n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if use_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model_transfer(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    train_loss = train_loss/len(train_loader.sampler)\n    valid_loss = valid_loss/len(valid_loader.sampler)\n        \n    # print training/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model_transfer.state_dict(), 'model_transfer_cifar.pt')\n        valid_loss_min = valid_loss","metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:01:48.255641Z","iopub.execute_input":"2021-11-19T14:01:48.255934Z","iopub.status.idle":"2021-11-19T14:22:29.246815Z","shell.execute_reply.started":"2021-11-19T14:01:48.255901Z","shell.execute_reply":"2021-11-19T14:22:29.245732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4 Test\nFirst, let's test the CNN model from scratch","metadata":{}},{"cell_type":"code","source":"# Load the saved model\nmodel.load_state_dict(torch.load('model_cifar.pt'))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:22:29.248690Z","iopub.execute_input":"2021-11-19T14:22:29.249270Z","iopub.status.idle":"2021-11-19T14:22:29.260702Z","shell.execute_reply.started":"2021-11-19T14:22:29.249227Z","shell.execute_reply":"2021-11-19T14:22:29.259992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# obtain one batch of test images\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\nimages.numpy()\n\n# move model inputs to cuda, if GPU available\nif use_gpu:\n    images = images.cuda()\n\n# get sample outputs\noutput = model(images)\n# convert output probabilities to predicted class\n_, preds_tensor = torch.max(output, 1)\npreds = np.squeeze(preds_tensor.numpy()) if not use_gpu else np.squeeze(preds_tensor.cpu().numpy())\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    imshow(images.cpu()[idx])\n    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))","metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:22:29.262155Z","iopub.execute_input":"2021-11-19T14:22:29.262764Z","iopub.status.idle":"2021-11-19T14:22:30.520602Z","shell.execute_reply.started":"2021-11-19T14:22:29.262726Z","shell.execute_reply":"2021-11-19T14:22:30.519686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see the transfer learning model ","metadata":{}},{"cell_type":"code","source":"# Load the saved model\nmodel_transfer.load_state_dict(torch.load('./model_transfer_cifar.pt'))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:22:30.521869Z","iopub.execute_input":"2021-11-19T14:22:30.522116Z","iopub.status.idle":"2021-11-19T14:22:30.586073Z","shell.execute_reply.started":"2021-11-19T14:22:30.522082Z","shell.execute_reply":"2021-11-19T14:22:30.585464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# obtain one batch of test images\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\nimages.numpy()\n\n# move model inputs to cuda, if GPU available\nif use_gpu:\n    images = images.cuda()\n\n# get sample outputs\noutput = model_transfer(images)\n# convert output probabilities to predicted class\n_, preds_tensor = torch.max(output, 1)\npreds = np.squeeze(preds_tensor.numpy()) if not use_gpu else np.squeeze(preds_tensor.cpu().numpy())\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    imshow(images.cpu()[idx])\n    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))","metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:22:30.589106Z","iopub.execute_input":"2021-11-19T14:22:30.589545Z","iopub.status.idle":"2021-11-19T14:22:31.626736Z","shell.execute_reply.started":"2021-11-19T14:22:30.589486Z","shell.execute_reply":"2021-11-19T14:22:31.625555Z"},"trusted":true},"execution_count":null,"outputs":[]}]}